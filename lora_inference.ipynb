{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEWy4BXxFsFy18C5W4C5XM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackma-00/peft-of-a-llm/blob/main/lora_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unsloth"
      ],
      "metadata": {
        "id": "azPTHt1MO9Bm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also get the latest version of bitsandbytes\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR7RlphbRy7u",
        "outputId": "c41143ec-c0fe-4d34-a0d0-509e99d0f259"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U polygon-api-client"
      ],
      "metadata": {
        "id": "JSnwI2lXjpSZ",
        "outputId": "6a5202b5-7264-4969-9520-62e0e5bf3157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polygon-api-client\n",
            "  Downloading polygon_api_client-1.14.2-py3-none-any.whl.metadata (889 bytes)\n",
            "Requirement already satisfied: certifi<2025.0.0,>=2022.5.18 in /usr/local/lib/python3.10/dist-packages (from polygon-api-client) (2024.8.30)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=1.26.9 in /usr/local/lib/python3.10/dist-packages (from polygon-api-client) (2.2.3)\n",
            "Collecting websockets<13.0,>=10.3 (from polygon-api-client)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading polygon_api_client-1.14.2-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, polygon-api-client\n",
            "Successfully installed polygon-api-client-1.14.2 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from polygon import RESTClient\n",
        "import json\n",
        "\n",
        "# Your Polygon API Key\n",
        "client = RESTClient(api_key=\"l3Ae5NltOnv2MqCVkfs62CSIKzWs_Z6H\")\n",
        "\n",
        "# List of tickers to track\n",
        "tickers = [\"SPY\", \"DIA\", \"QQQ\", \"IWM\", \"VXX\"]\n",
        "\n",
        "# Collect data in a structured format\n",
        "data = []\n",
        "\n",
        "for ticker in tickers:\n",
        "    quote = client.get_previous_close_agg(ticker=ticker)\n",
        "\n",
        "    # Access attributes directly from the first result\n",
        "    formatted_quote = {\n",
        "        \"ticker\": quote[0].ticker,\n",
        "        \"open\": quote[0].open,\n",
        "        \"high\": quote[0].high,\n",
        "        \"low\": quote[0].low,\n",
        "        \"close\": quote[0].close,\n",
        "        \"volume\": quote[0].volume,\n",
        "        \"timestamp\": quote[0].timestamp,\n",
        "        \"vwap\": quote[0].vwap,\n",
        "    }\n",
        "    data.append(formatted_quote)\n",
        "\n",
        "# Convert the data to a JSON string for LLM analysis\n",
        "formatted_data = json.dumps(data, indent=4)\n",
        "print(formatted_data)\n"
      ],
      "metadata": {
        "id": "G7-vvRPKjyT3",
        "outputId": "dfe4d21d-21a7-4756-b41a-ddebcf44bb21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"ticker\": \"SPY\",\n",
            "        \"open\": 599.52,\n",
            "        \"high\": 600.86,\n",
            "        \"low\": 595.2,\n",
            "        \"close\": 597.53,\n",
            "        \"volume\": 42365646.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 597.7636\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"DIA\",\n",
            "        \"open\": 446.61,\n",
            "        \"high\": 448.4,\n",
            "        \"low\": 445.4,\n",
            "        \"close\": 447.56,\n",
            "        \"volume\": 2892225.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 447.2456\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"QQQ\",\n",
            "        \"open\": 509.9,\n",
            "        \"high\": 511.4525,\n",
            "        \"low\": 504.2625,\n",
            "        \"close\": 506.59,\n",
            "        \"volume\": 26166808.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 507.2417\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"IWM\",\n",
            "        \"open\": 241.49,\n",
            "        \"high\": 244.98,\n",
            "        \"low\": 241.39,\n",
            "        \"close\": 242.4,\n",
            "        \"volume\": 33025021.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 243.071\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"VXX\",\n",
            "        \"open\": 44.39,\n",
            "        \"high\": 46.2463,\n",
            "        \"low\": 43.88,\n",
            "        \"close\": 43.88,\n",
            "        \"volume\": 3644270.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 44.716\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Here are the aggregated values: {}\".format(formatted_data))"
      ],
      "metadata": {
        "id": "hTMd0DkiumgV",
        "outputId": "70811a94-9a07-426f-b08c-d5cb8fa3ceb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the aggregated values: [\n",
            "    {\n",
            "        \"ticker\": \"SPY\",\n",
            "        \"open\": 599.52,\n",
            "        \"high\": 600.86,\n",
            "        \"low\": 595.2,\n",
            "        \"close\": 597.53,\n",
            "        \"volume\": 42365646.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 597.7636\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"DIA\",\n",
            "        \"open\": 446.61,\n",
            "        \"high\": 448.4,\n",
            "        \"low\": 445.4,\n",
            "        \"close\": 447.56,\n",
            "        \"volume\": 2892225.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 447.2456\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"QQQ\",\n",
            "        \"open\": 509.9,\n",
            "        \"high\": 511.4525,\n",
            "        \"low\": 504.2625,\n",
            "        \"close\": 506.59,\n",
            "        \"volume\": 26166808.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 507.2417\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"IWM\",\n",
            "        \"open\": 241.49,\n",
            "        \"high\": 244.98,\n",
            "        \"low\": 241.39,\n",
            "        \"close\": 242.4,\n",
            "        \"volume\": 33025021.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 243.071\n",
            "    },\n",
            "    {\n",
            "        \"ticker\": \"VXX\",\n",
            "        \"open\": 44.39,\n",
            "        \"high\": 46.2463,\n",
            "        \"low\": 43.88,\n",
            "        \"close\": 43.88,\n",
            "        \"volume\": 3644270.0,\n",
            "        \"timestamp\": 1732568400000,\n",
            "        \"vwap\": 44.716\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer, TextStreamer\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model_name = \"jackma-00/lora_model_1b\" # Model name\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name, # YOUR MODEL YOU USED FOR TRAINING\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "system_prompt = \"You are a financial consultant. Answer your client's questions using yesterday's closing aggregates for the following key tickers: {}\".format(formatted_data)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"How should I allocate additional 10k to my portfolio?\"\n",
        "    },\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ],
      "metadata": {
        "id": "w8hpsFLisg_P",
        "outputId": "05d96f6a-9799-4936-f5b1-86257f10e73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.11.11: Fast Llama patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Based on the latest closing data provided for the specified tickers (SPY, DIA, QQQ, IWM, VXX) and considering today's market, it appears that there is no clear-cut way to allocate the additional $10,000. \n",
            "\n",
            "These are high-cap stocks that can potentially offer substantial long-term gains due to the growth and dividend payments, but the current market conditions may not align in your favor. The value of these stocks could potentially decrease further due to the volatility in the market.\n",
            "\n",
            "At this point, a financial consultant may advise caution rather than aggressive allocation. The best time to make an investment is after conducting\n"
          ]
        }
      ]
    }
  ]
}